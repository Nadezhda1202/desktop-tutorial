# Sherpa AI Server

**Sherpa AI Server** – это веб-сервисное приложение, предназначенное для обучения, использования и дообучения больших языковых моделей (LLM) внутри закрытого контура корпораций. Sherpa AI Server объединяет в себе векторное хранилище документов, управление офлайн-моделями, поддержку разнообразных моделей искусственного интеллекта – с разным размером, с квантованием и без, их запуск на GPU или CPU, проектирование цепочек обработки данных, доступ через API, платформу роботизации и веб-интерфейс, и многое другое.

Sherpa AI Server – это Центр искусственного интеллекта, который содержит функционал:

·         большие языковые модели (LLM) в закрытом контуре;

·         веб-чат для сотрудников компании в стиле ChatGPT с историей и диалогами;

·         поддержка русского языка;

·         ответы на вопросы по собственным документам;

·         встроенное векторное хранилище документов;

·         API для любых приложений компании, совместимое с OpenAI;

·         интеграция с Sherpa RPA - работа с LLM из сценариев роботов;

·         безопасность, конфиденциальность, мониторинг, аудит;

·         многопользовательский и многопоточный режим;

·         выбор из более 300 доступных языковых моделей;

·         работа с CPU / GPU и самыми современными методами квантования и батчинга нейросетей;

·         возможность интеграции с любой отечественной RPA-платформой посредством API.

Sherpa AI Server обладает широким спектром возможностей и функциональности, которые позволяют применяться как:

·         чат-бот для поддержки клиентов;

·         чат-бот для поддержки внутренних пользователей;

·         чат-бот для ответов по содержимому корпоративных документов и баз знаний;

·         конструктор документов, генератор договоров, вакансий, отчётов, аналитических записок;

·         робот-юрист, робот-продавец, робот-кадровик, робот-интервьювер, робот-документовед и т.д.;

·         извлечение структурированных и неструктурированных данных из документов, в том числе, сканированных и их заведение в информационные системы;

·         генерация контент-планов, блог-постов, статей, обзоров, комментариев, пресс-релизов, дайджестов, email-писем, рассылок, презентаций и т.д.;

·         генерация кода, юнит-тестов, макросов, запросов, комментариев и документации к коду;

·         семантический анализ и анализ тональности комментариев и отзывов клиентов;

·         текстовый и голосовой BI (Business Intelligence) для корпоративных данных;

·         массовое копирование правок документов, отслеживание и поддержка изменений нормативной документации.

## Рекомендации к системным характеристикам компьютера

При развертывании Sherpa AI Server на GPU рекомендуется использовать компьютеры со следующими характеристиками:

<table data-header-hidden><thead><tr><th width="236"></th><th></th></tr></thead><tbody><tr><td>Процессор</td><td>от 8 ядер</td></tr><tr><td>Оперативная память</td><td>от 32 Гб (рекомендуется удвоенное значение от объема доступной видеопамяти)</td></tr><tr><td>Место на диске</td><td>от 150 Гб</td></tr><tr><td>Операционная система</td><td>Docker-совместимый Linux, рекомендуется Ubuntu 22+, однако возможна установка и на других дистрибутивах</td></tr><tr><td>Программное обеспечение</td><td>Docker, Docker Compose, NVIDIA Docker Toolkit (nvidia-docker2) на хост-системе, чтобы обеспечить доступ контейнера к GPU хоста. Можно установить отдельно или в составе NVIDIA CUDA Toolkit</td></tr><tr><td>Объем видеопамяти</td><td>от 16 Гб (зависит от размера модели и размера окна контекста, для моделей 7B-13B рекомендуется 24 Гб)</td></tr><tr><td>Требования к видеокарте</td><td>Compute Capability не ниже 8.0 (уточнить для конкретной видеокарты можно по следующей ссылке: https://developer.nvidia.com/cuda-gpus).</td></tr><tr><td>Совместимые модели видеокарт</td><td><p><strong>Примечание</strong>: <em>среди консьюмерских видеокарт наилучшее сочетание цена-производительность для моделей размерностью 7b-13b обеспечивается видеокартой NVidia RTX 3090 24 Gb.</em></p><p><em>Среди специализированных видеокарт достаточно хорошее сочетание цена-производительность для моделей размерностью 7b-13b обеспечивается видеокартой NVidia A10 24 Gb</em></p><p><em>При наличии в контуре видеокарт уровня Tesla A100 рекомендуется использовать их. При отсутствии в контуре таких видеокарт рекомендуется собрать систему из альтернативных видеокарт - см. ниже.</em></p></td></tr><tr><td>NVIDIA Data Center Products</td><td>NVIDIA A2, NVIDIA A16, NVIDIA A10, NVIDIA A30, NVIDIA A40, NVIDIA A100, NVIDIA L4, NVIDIA L40, NVIDIA H100.</td></tr><tr><td>NVIDIA RTX Desktop</td><td>RTX A4000, RTX A5000, RTX A6000, RTX 6000</td></tr><tr><td>NVIDIA RTX Mobile</td><td>RTX A2000, RTX A3000, RTX A4000, RTX A5000</td></tr><tr><td>GeForce Products</td><td>Geforce RTX 3060, Geforce RTX 3060 Ti, GeForce RTX 3070, GeForce RTX 3070 Ti, GeForce RTX 3080, GeForce RTX 3080 Ti, GeForce RTX 3090, GeForce RTX 3090 Ti, GeForce RTX 4070 Ti, GeForce RTX 4080, GeForce RTX 4090</td></tr><tr><td>GeForce Notebook Products</td><td>GeForce RTX 3050, GeForce RTX 3050 Ti, GeForce RTX 3060, GeForce RTX 3060 Ti, GeForce RTX 3070, GeForce RTX 3070 Ti, GeForce RTX 3080, GeForce RTX 3080 Ti, GeForce RTX 4050, GeForce RTX 4060, GeForce RTX 4070, GeForce RTX 4080, GeForce RTX 4090</td></tr><tr><td>Jetson Products</td><td>Jetson AGX Orin, Jetson Orin NX, Jetson Orin Nano</td></tr></tbody></table>
